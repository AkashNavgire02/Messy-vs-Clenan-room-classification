{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Messy vs clean room.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkashNavgire02/Messy-vs-Clenan-room-classification/blob/main/Messy_vs_clean_room.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4vgNV8ODDd0"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2HWzsU4EPjz"
      },
      "source": [
        "train_dir = \"/content/drive/My Drive/New folder/Messy vs clean room/images/train\"\n",
        "validation_dir = \"/content/drive/My Drive/New folder/Messy vs clean room/images/val\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LE2dw4wEu1x"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFm4oHJV5sfQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bfd9aee-aade-4feb-8fe5-c15b40101804"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150)) \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 192 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk9kgrkPmISl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNFPePGR5vTh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "beb6545c-506d-4d1e-9e1d-554af3d43593"
      },
      "source": [
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (150, 150))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcYDWD9w51vY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1db02d0a-7ddc-4a1e-b69a-e5f09bef7bc3"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='selu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='selu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='selu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(), \n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(3000, activation='selu'), \n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(2000, activation='selu'), \n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(1500, activation='selu'), \n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(1000, activation='selu'), \n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(500, activation='selu'), \n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(300, activation='selu'), \n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(200, activation='selu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(100, activation='selu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(50, activation='selu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(20, activation='selu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('Organic') \n",
        "    # and 1 for the other ('Recycled')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3000)              55491000  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2000)              6002000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1500)              3001500   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1500)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1000)              1501000   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 300)               150300    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               60200     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 20)                1020      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 66,756,275\n",
            "Trainable params: 66,756,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WfcY4oM6SH2"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, \n",
        "                        verbose=1, mode='auto',restore_best_weights=True)\n",
        "model.compile(optimizer=RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiWYaGjM6W5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "14b376b1-1ba5-49c4-aff5-3744b311e671"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              steps_per_epoch=50,epochs=10,\n",
        "                              validation_steps=5,\n",
        "                              verbose=2, callbacks=[monitor])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5 batches). You may need to use the repeat() function when building your dataset.\n",
            "10/10 - 10s - loss: 1.2023 - acc: 0.5104 - val_loss: 0.7066 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.9475 - acc: 0.6458\n",
            "Epoch 3/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.8580 - acc: 0.6927\n",
            "Epoch 4/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.8473 - acc: 0.6562\n",
            "Epoch 5/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.8431 - acc: 0.7292\n",
            "Epoch 6/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.9227 - acc: 0.7083\n",
            "Epoch 7/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.4502 - acc: 0.8281\n",
            "Epoch 8/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.6599 - acc: 0.7917\n",
            "Epoch 9/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.4191 - acc: 0.8542\n",
            "Epoch 10/10\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "10/10 - 10s - loss: 0.3348 - acc: 0.8906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onbyrV_d81O9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31e1ca56-8604-4dae-c021-b7ef5714ba06"
      },
      "source": [
        "test2_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_dir = \"/content/drive/My Drive/New folder/Messy vs clean room/images/test\"\n",
        "test_generator =  test2_datagen.flow_from_directory(test_dir,\n",
        "                                                    batch_size=3,\n",
        "                                                    class_mode  = 'input',\n",
        "                                                    target_size = (150, 150),\n",
        "                                                    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulZYzoPn6ebH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "3073400e-1d29-475b-b518-b5a445c1883f"
      },
      "source": [
        "y_prob = model.predict(test_generator)\n",
        "y_prob\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.97520846],\n",
              "       [0.11275363],\n",
              "       [0.9610413 ],\n",
              "       [0.98931754],\n",
              "       [0.9998449 ],\n",
              "       [0.9966086 ],\n",
              "       [0.38185948],\n",
              "       [0.99459076],\n",
              "       [0.9995593 ],\n",
              "       [0.40799528]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pcnNJ-ef8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "1def1056-a779-4a01-9686-d0ba45db3d14"
      },
      "source": [
        "y_pred = [\"Messy\" if probs > 0.5 else \"Clean\" for probs in y_prob]\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Messy',\n",
              " 'Clean',\n",
              " 'Messy',\n",
              " 'Messy',\n",
              " 'Messy',\n",
              " 'Messy',\n",
              " 'Clean',\n",
              " 'Messy',\n",
              " 'Messy',\n",
              " 'Clean']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}